{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing stacking for each fold and then by each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sys import path\n",
    "path.append(\"..\")\n",
    "from src.utils import get_classifier, load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"darknet\"\n",
    "CASE = \"2\" if DATA_SOURCE == \"darknet\" else \"3\"\n",
    "\n",
    "strategies = [\"igcngru_features\", \"idarkvec\", \"features\"]\n",
    "STRATS_SUFIX = \"-\".join(sorted(strategies))\n",
    "\n",
    "strategies.sort()\n",
    "k_n = \"k3\"\n",
    "data_dir = \"../data/2022/input/stacking_predictions/out\"\n",
    "base_output = f\"../data/2022/output/{DATA_SOURCE}/{STRATS_SUFIX}/{CASE}\"\n",
    "n_folds = 10\n",
    "classifier = \"lr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['censys', 'mirai', 'unk_bruteforcer', 'unk_spammer', 'driftnet',\n",
       "       'shodan', 'internetcensus', 'onyphe', 'securitytrails', 'ipip',\n",
       "       'intrinsec', 'shadowserver', 'u_mich', 'unk_exploiter'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"../data/2022/input/stacking_predictions/out/k3/{DATA_SOURCE}/test/idarkvec_20221021_fold00.csv\")\n",
    "df.y_true.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "probs_cols = [\n",
    "    \"censys\",\n",
    "    \"driftnet\",\n",
    "    \"internetcensus\",\n",
    "    \"intrinsec\",\n",
    "    \"ipip\",\n",
    "    \"mirai\",\n",
    "    \"onyphe\",\n",
    "    \"rapid7\",\n",
    "    \"securitytrails\",\n",
    "    \"shadowserver\",\n",
    "    \"shodan\",\n",
    "    \"u_mich\",\n",
    "    \"unk_bruteforcer\",\n",
    "    \"unk_exploiter\",\n",
    "    \"unk_spammer\",\n",
    "    \"unknown\"\n",
    "]\n",
    "probs_cols.sort()\n",
    "\n",
    "label_to_idx = {l: idx for idx, l in enumerate(probs_cols)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['censys',\n",
       " 'driftnet',\n",
       " 'internetcensus',\n",
       " 'intrinsec',\n",
       " 'ipip',\n",
       " 'mirai',\n",
       " 'onyphe',\n",
       " 'rapid7',\n",
       " 'securitytrails',\n",
       " 'shadowserver',\n",
       " 'shodan',\n",
       " 'u_mich',\n",
       " 'unk_bruteforcer',\n",
       " 'unk_exploiter',\n",
       " 'unk_spammer',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_strat_name(file_path):\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    tokens = file_name.split(\"_\")\n",
    "    tokens.pop()\n",
    "    tokens.pop()\n",
    "    return '_'.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def load_probs(data_dir, strategies, k_n, data_source, day, fold, train_test, probs_cols):\n",
    "    X = []\n",
    "    files = glob(f\"{data_dir}/{k_n}/{data_source}/{train_test}/*_{day}_fold0{fold}.csv\")\n",
    "\n",
    "    idxs_files = [[i, get_strat_name(f)] for i, f in enumerate(files)]\n",
    "    idxs_files.sort(key=lambda x: x[1])\n",
    "    files = [files[i] for i, _ in idxs_files]\n",
    "\n",
    "    for file_path in files:\n",
    "        strat = get_strat_name(file_path)\n",
    "        if strat in strategies:\n",
    "            df = pd.read_csv(file_path).sort_values(by=[\"src_ip\"])\n",
    "            #df = df[df.y_true != \"unknown\"]\n",
    "            X.append(df[probs_cols].values)\n",
    "\n",
    "    return np.hstack(X), df.y_true.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_probs(data_dir, strategies, k_n, DATA_SOURCE, '20221021', 0, \"train\", probs_cols)\n",
    "X_test, y_test = load_probs(data_dir, strategies, k_n, DATA_SOURCE, '20221021', 0, \"test\", probs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>censys</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>11.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driftnet</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internetcensus</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>23.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intrinsec</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipip</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mirai</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>804.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onyphe</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>securitytrails</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadowserver</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shodan</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_mich</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unk_bruteforcer</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unk_exploiter</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unk_spammer</th>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>49.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.95542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.801966</td>\n",
       "      <td>0.729992</td>\n",
       "      <td>0.751703</td>\n",
       "      <td>987.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.983765</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.963743</td>\n",
       "      <td>987.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision    recall  f1-score    support\n",
       "censys            1.000000  0.818182  0.900000   11.00000\n",
       "driftnet          1.000000  1.000000  1.000000   25.00000\n",
       "internetcensus    0.956522  0.956522  0.956522   23.00000\n",
       "intrinsec         1.000000  1.000000  1.000000    1.00000\n",
       "ipip              1.000000  1.000000  1.000000    1.00000\n",
       "mirai             1.000000  1.000000  1.000000  804.00000\n",
       "onyphe            1.000000  1.000000  1.000000    9.00000\n",
       "securitytrails    1.000000  1.000000  1.000000    2.00000\n",
       "shadowserver      1.000000  1.000000  1.000000   29.00000\n",
       "shodan            0.500000  0.333333  0.400000    3.00000\n",
       "u_mich            1.000000  1.000000  1.000000    1.00000\n",
       "unk_bruteforcer   0.600000  0.107143  0.181818   28.00000\n",
       "unk_exploiter     0.000000  0.000000  0.000000    1.00000\n",
       "unk_spammer       0.972973  0.734694  0.837209   49.00000\n",
       "unknown           0.000000  0.000000  0.000000    0.00000\n",
       "accuracy          0.955420  0.955420  0.955420    0.95542\n",
       "macro avg         0.801966  0.729992  0.751703  987.00000\n",
       "weighted avg      0.983765  0.955420  0.963743  987.00000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_test, preds, output_dict=True, zero_division=0.0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20221021',\n",
       " '20221022',\n",
       " '20221023',\n",
       " '20221024',\n",
       " '20221025',\n",
       " '20221026',\n",
       " '20221027',\n",
       " '20221028',\n",
       " '20221029',\n",
       " '20221030',\n",
       " '20221031']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = sorted([ f.split('/')[-1].split('_')[-2] for f in glob(f\"{data_dir}/{k_n}/{DATA_SOURCE}/test/idarkvec*_fold00.csv\") ])\n",
    "days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following cells we run the stacking for each fold and also take F1 by fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "strats_posfix = '-'.join(sorted(strategies))\n",
    "reporte = {}\n",
    "for day in days:\n",
    "    reporte[day] = {}\n",
    "    for fold in np.arange(10):\n",
    "        X_train, y_train = load_probs(data_dir, strategies, k_n, DATA_SOURCE, day, fold, \"train\", probs_cols)\n",
    "        X_test, y_test = load_probs(data_dir, strategies, k_n, DATA_SOURCE, day, fold, \"test\", probs_cols)\n",
    "        clf = get_classifier(classifier)\n",
    "\n",
    "        # applying undersampling.\n",
    "        n = pd.value_counts(y_train).values[2]\n",
    "        us = RandomUnderSampler(sampling_strategy={\"unknown\": n, \"mirai\": n}, random_state=42)\n",
    "        #X_train, y_train = us.fit_resample(X_train, y_train)\n",
    "        us_idxs, y_train = us.fit_resample(np.arange(X_train.shape[0]).reshape(-1, 1), y_train)\n",
    "        us_idxs = us_idxs.reshape(-1)\n",
    "        X_train = X_train[us_idxs]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        probas = clf.predict_proba(X_test)\n",
    "        reporte[day][fold] = {}\n",
    "        reporte[day][fold][\"y\"] = y_test\n",
    "        reporte[day][fold][\"preds\"] = preds\n",
    "        output_dir = f\"{base_output}/stacking_data/{day}/{fold}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        np.savez(f\"{output_dir}/data.npz\",\n",
    "                X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test,\n",
    "                probas=probas,\n",
    "                us_idxs=us_idxs)\n",
    "        dump(clf, f\"{output_dir}/{classifier}.joblib\")\n",
    "\n",
    "output_dir = f\"{base_output}/report\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(f\"{output_dir}/{k_n}.pkl\", 'wb') as fd:\n",
    "    pickle.dump(reporte, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "report_path = f\"{base_output}/report/{k_n}.pkl\"\n",
    "reporte = load_pickle(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:35<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "class_scores = {}\n",
    "for label in tqdm(probs_cols + [\"macro avg\"]):\n",
    "    class_scores[label] = []\n",
    "    for day in reporte:\n",
    "        y, preds = [], []\n",
    "        for fold in reporte[day]:\n",
    "            y.append(reporte[day][fold][\"y\"])\n",
    "            preds.append(reporte[day][fold][\"preds\"])\n",
    "\n",
    "        y = np.hstack(y)\n",
    "        preds = np.hstack(preds)\n",
    "\n",
    "        scores = classification_report(\n",
    "            y, preds, labels=np.unique(y), zero_division=0, output_dict=True\n",
    "        )\n",
    "        if label in scores:\n",
    "            class_scores[label].append(scores[label][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censys;0.98\n",
      "driftnet;0.99\n",
      "internetcensus;0.99\n",
      "intrinsec;0.86\n",
      "ipip;0.97\n",
      "mirai;0.99\n",
      "onyphe;0.99\n",
      "rapid7;0.99\n",
      "securitytrails;1.0\n",
      "shadowserver;0.99\n",
      "shodan;0.85\n",
      "u_mich;0.98\n",
      "unk_bruteforcer;0.74\n",
      "unk_exploiter;0.32\n",
      "unk_spammer;0.86\n",
      "unknown;nan\n",
      "macro avg;0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/welton/DarkNet/.env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/welton/DarkNet/.env/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for label in probs_cols + [\"macro avg\"]:\n",
    "    v = np.trunc(np.mean(class_scores[label])* 100) / 100\n",
    "    print(f\"{label};{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censys;0.0\n",
      "driftnet;0.0\n",
      "internetcensus;0.0\n",
      "intrinsec;0.03\n",
      "ipip;0.03\n",
      "mirai;0.0\n",
      "onyphe;0.0\n",
      "rapid7;0.0\n",
      "securitytrails;0.0\n",
      "shadowserver;0.0\n",
      "shodan;0.02\n",
      "u_mich;0.02\n",
      "unk_bruteforcer;0.03\n",
      "unk_exploiter;0.25\n",
      "unk_spammer;0.01\n",
      "unknown;nan\n",
      "macro avg;0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/welton/DarkNet/.env/lib/python3.8/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/welton/DarkNet/.env/lib/python3.8/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/welton/DarkNet/.env/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for label in probs_cols + [\"macro avg\"]:\n",
    "    v = np.trunc(np.std(class_scores[label]) * 100) / 100\n",
    "    print(f\"{label};{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
