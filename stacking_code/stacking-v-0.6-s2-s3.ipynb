{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing stacking for each fold and then by each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sys import path\n",
    "path.append(\"..\")\n",
    "from src.utils import get_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"honeypot\"\n",
    "CASE = \"2\" if DATA_SOURCE == \"darknet\" else \"3\"\n",
    "\n",
    "strategies = [\"igcngru_features\", \"idarkvec\", \"features\"]\n",
    "STRATS_SUFIX = \"-\".join(sorted(strategies))\n",
    "\n",
    "strategies.sort()\n",
    "k_n = \"k3\"\n",
    "data_dir = \"../data/2022/input/stacking_predictions/out\"\n",
    "base_output = f\"../data/2022/output/{DATA_SOURCE}/{STRATS_SUFIX}/{CASE}\"\n",
    "n_folds = 10\n",
    "classifier = \"lr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unk_spammer', 'mirai', 'shadowserver', 'unk_bruteforcer',\n",
       "       'securitytrails', 'censys', 'driftnet', 'internetcensus', 'onyphe',\n",
       "       'unk_exploiter', 'shodan', 'intrinsec', 'ipip', 'u_mich'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"../data/2022/input/stacking_predictions/out/k3/{DATA_SOURCE}/test/idarkvec_20221021_fold00.csv\")\n",
    "df.y_true.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_cols = [\n",
    "    \"censys\",\n",
    "    \"driftnet\",\n",
    "    \"internetcensus\",\n",
    "    \"intrinsec\",\n",
    "    \"ipip\",\n",
    "    \"mirai\",\n",
    "    \"onyphe\",\n",
    "    \"rapid7\",\n",
    "    \"securitytrails\",\n",
    "    \"shadowserver\",\n",
    "    \"shodan\",\n",
    "    \"u_mich\",\n",
    "    \"unk_bruteforcer\",\n",
    "    \"unk_exploiter\",\n",
    "    \"unk_spammer\",\n",
    "    \"unknown\"\n",
    "]\n",
    "probs_cols.sort()\n",
    "\n",
    "label_to_idx = {l: idx for idx, l in enumerate(probs_cols)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['censys',\n",
       " 'driftnet',\n",
       " 'internetcensus',\n",
       " 'intrinsec',\n",
       " 'ipip',\n",
       " 'mirai',\n",
       " 'onyphe',\n",
       " 'rapid7',\n",
       " 'securitytrails',\n",
       " 'shadowserver',\n",
       " 'shodan',\n",
       " 'u_mich',\n",
       " 'unk_bruteforcer',\n",
       " 'unk_exploiter',\n",
       " 'unk_spammer',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strat_name(file_path):\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    tokens = file_name.split(\"_\")\n",
    "    tokens.pop()\n",
    "    tokens.pop()\n",
    "    return '_'.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probs(data_dir, strategies, k_n, data_source, day, fold, train_test, probs_cols):\n",
    "    X = []\n",
    "    files = glob(f\"{data_dir}/{k_n}/{data_source}/{train_test}/*_{day}_fold0{fold}.csv\")\n",
    "\n",
    "    idxs_files = [[i, get_strat_name(f)] for i, f in enumerate(files)]\n",
    "    idxs_files.sort(key=lambda x: x[1])\n",
    "    files = [files[i] for i, _ in idxs_files]\n",
    "\n",
    "    for file_path in files:\n",
    "        strat = get_strat_name(file_path)\n",
    "        if strat in strategies:\n",
    "            df = pd.read_csv(file_path)\n",
    "            #df = df[df.y_true != \"unknown\"]\n",
    "            X.append(df[probs_cols].values)\n",
    "\n",
    "    return np.hstack(X), df.y_true.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_probs(data_dir, strategies, k_n, DATA_SOURCE, '20221021', 0, \"train\", probs_cols)\n",
    "X_test, y_test = load_probs(data_dir, strategies, k_n, DATA_SOURCE, '20221021', 0, \"test\", probs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>censys</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driftnet</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internetcensus</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intrinsec</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipip</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mirai</th>\n",
       "      <td>0.998956</td>\n",
       "      <td>0.989659</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>967.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onyphe</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>securitytrails</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadowserver</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shodan</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_mich</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unk_bruteforcer</th>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unk_exploiter</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unk_spammer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.957576</td>\n",
       "      <td>0.957576</td>\n",
       "      <td>0.957576</td>\n",
       "      <td>0.957576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.826740</td>\n",
       "      <td>0.737631</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>1320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.995779</td>\n",
       "      <td>0.957576</td>\n",
       "      <td>0.974839</td>\n",
       "      <td>1320.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision    recall  f1-score      support\n",
       "censys            1.000000  1.000000  1.000000    13.000000\n",
       "driftnet          1.000000  0.971429  0.985507    35.000000\n",
       "internetcensus    1.000000  1.000000  1.000000    23.000000\n",
       "intrinsec         0.000000  0.000000  0.000000     1.000000\n",
       "ipip              1.000000  0.500000  0.666667     2.000000\n",
       "mirai             0.998956  0.989659  0.994286   967.000000\n",
       "onyphe            0.909091  1.000000  0.952381    10.000000\n",
       "securitytrails    1.000000  1.000000  1.000000     2.000000\n",
       "shadowserver      1.000000  1.000000  1.000000    29.000000\n",
       "shodan            0.500000  0.333333  0.400000     3.000000\n",
       "u_mich            1.000000  1.000000  1.000000     1.000000\n",
       "unk_bruteforcer   0.993056  0.861446  0.922581   166.000000\n",
       "unk_exploiter     1.000000  0.666667  0.800000     6.000000\n",
       "unk_spammer       1.000000  0.741935  0.851852    62.000000\n",
       "unknown           0.000000  0.000000  0.000000     0.000000\n",
       "accuracy          0.957576  0.957576  0.957576     0.957576\n",
       "macro avg         0.826740  0.737631  0.771552  1320.000000\n",
       "weighted avg      0.995779  0.957576  0.974839  1320.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_test, preds, output_dict=True, zero_division=0.0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20221021',\n",
       " '20221022',\n",
       " '20221023',\n",
       " '20221024',\n",
       " '20221025',\n",
       " '20221026',\n",
       " '20221027',\n",
       " '20221028',\n",
       " '20221029',\n",
       " '20221030',\n",
       " '20221031']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = sorted([ f.split('/')[-1].split('_')[-2] for f in glob(f\"{data_dir}/{k_n}/{DATA_SOURCE}/test/idarkvec*_fold00.csv\") ])\n",
    "days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following cells we run the stacking for each fold and also take F1 by fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "strats_posfix = '-'.join(sorted(strategies))\n",
    "reporte = {}\n",
    "for day in days:\n",
    "    reporte[day] = {}\n",
    "    for fold in np.arange(10):\n",
    "        X_train, y_train = load_probs(data_dir, strategies, k_n, DATA_SOURCE, day, fold, \"train\", probs_cols)\n",
    "        X_test, y_test = load_probs(data_dir, strategies, k_n, DATA_SOURCE, day, fold, \"test\", probs_cols)\n",
    "        clf = get_classifier(classifier)\n",
    "\n",
    "        # applying undersampling.\n",
    "        n = pd.value_counts(y_train).values[2]\n",
    "        us = RandomUnderSampler(sampling_strategy={\"unknown\": n})\n",
    "        X_train, y_train = us.fit_resample(X_train, y_train)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        probas = clf.predict_proba(X_test)\n",
    "        reporte[day][fold] = {}\n",
    "        reporte[day][fold][\"y\"] = y_test\n",
    "        reporte[day][fold][\"preds\"] = preds\n",
    "        output_dir = f\"{base_output}/stacking_data/{day}/{fold}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        np.savez(f\"{output_dir}/data.npz\",\n",
    "                X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test,\n",
    "                probas=probas)\n",
    "        dump(clf, f\"{output_dir}/{classifier}.joblib\")\n",
    "\n",
    "output_dir = f\"{base_output}/report\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(f\"{output_dir}/{k_n}.pkl\", 'wb') as fd:\n",
    "    pickle.dump(reporte, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mirai              6559\n",
       "unk_bruteforcer    1346\n",
       "unknown            1346\n",
       "unk_spammer         521\n",
       "shadowserver        247\n",
       "driftnet            246\n",
       "internetcensus      197\n",
       "censys              123\n",
       "unk_exploiter        53\n",
       "shodan               26\n",
       "ipip                 18\n",
       "securitytrails       16\n",
       "intrinsec            14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:51<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "class_scores = {}\n",
    "for label in tqdm(probs_cols):\n",
    "    class_scores[label] = []\n",
    "    for day in reporte:\n",
    "        y, preds = [], []\n",
    "        for fold in reporte[day]:\n",
    "            y.append(reporte[day][fold][\"y\"])\n",
    "            preds.append(reporte[day][fold][\"preds\"])\n",
    "\n",
    "        y = np.hstack(y)\n",
    "        preds = np.hstack(preds)\n",
    "\n",
    "        scores = classification_report(\n",
    "            y, preds, labels=np.unique(y), zero_division=0, output_dict=True\n",
    "        )\n",
    "        if label in scores:\n",
    "            class_scores[label].append(scores[label][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censys;0.93\n",
      "driftnet;0.99\n",
      "internetcensus;0.98\n",
      "intrinsec;0.74\n",
      "ipip;0.61\n",
      "mirai;0.99\n",
      "onyphe;0.98\n",
      "rapid7;0.99\n",
      "securitytrails;1.0\n",
      "shadowserver;0.99\n",
      "shodan;0.78\n",
      "u_mich;0.94\n",
      "unk_bruteforcer;0.95\n",
      "unk_exploiter;0.9\n",
      "unk_spammer;0.83\n",
      "unknown;nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/welton/DarkNet/.env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/welton/DarkNet/.env/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for label in probs_cols:\n",
    "    v = np.trunc(np.mean(class_scores[label])* 100) / 100\n",
    "    print(f\"{label};{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
